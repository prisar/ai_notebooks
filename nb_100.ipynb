{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMa9jHCF7ZWcUaVSAyKX7D6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prisar/ai_notebooks/blob/main/nb_100.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Mh5XBulyWA_A"
      },
      "outputs": [],
      "source": [
        "# Authentication and service account setup\n",
        "from google.colab import auth\n",
        "from google.auth import default\n",
        "import os\n",
        "\n",
        "# Authenticate with Google Cloud\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Set project ID\n",
        "os.environ['GOOGLE_CLOUD_PROJECT'] = 'mrc-quant-ml'\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Install required packages\n",
        "!pip install -q google-genai google-cloud-aiplatform"
      ],
      "metadata": {
        "id": "OFCw1yheXdQ8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "059b3759",
        "outputId": "88c77da1-5e31-41c1-afc9-ac42196ffcb6"
      },
      "source": [
        "# Import and initialize\n",
        "from google.genai import Client\n",
        "from google.genai.types import Part, VideoMetadata, FileData\n",
        "\n",
        "def summarize_video_chunk(video_uri: str, start_offset: str, end_offset: str, prompt: str = \"Analyze this video and provide a summary.\"):\n",
        "    \"\"\"Summarizes a video chunk using the Gemini API.\"\"\"\n",
        "    client = Client(\n",
        "        vertexai=True,\n",
        "        project=\"mrc-quant-ml\",\n",
        "        location=\"us-central1\",  # Changed from \"global\"\n",
        "    )\n",
        "\n",
        "    response = client.models.generate_content(\n",
        "        model=\"gemini-2.0-flash-exp\",  # Updated model name\n",
        "        contents=[\n",
        "            Part(\n",
        "                video_metadata=VideoMetadata(\n",
        "                    fps=1,\n",
        "                    start_offset=start_offset,\n",
        "                    end_offset=end_offset\n",
        "                ),\n",
        "                file_data=FileData(\n",
        "                    file_uri=video_uri,\n",
        "                    mime_type=\"video/mp4\",\n",
        "                ),\n",
        "            ),\n",
        "            prompt\n",
        "        ],\n",
        "    )\n",
        "    return response.text\n",
        "\n",
        "# Batch processing optimization\n",
        "async def process_video_chunks_parallel(video_uri: str, chunk_duration: int = 150, max_workers: int = 4):\n",
        "    \"\"\"Process video chunks in parallel for better throughput.\"\"\"\n",
        "    import asyncio\n",
        "    from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "    # Get video duration first (you'll need to implement this)\n",
        "    total_duration = await get_video_duration(video_uri)\n",
        "\n",
        "    chunks = [(i, min(i + chunk_duration, total_duration))\n",
        "              for i in range(0, total_duration, chunk_duration)]\n",
        "\n",
        "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
        "        tasks = [\n",
        "            executor.submit(\n",
        "                summarize_video_chunk,\n",
        "                video_uri,\n",
        "                f\"{start}s\",\n",
        "                f\"{end}s\"\n",
        "            ) for start, end in chunks\n",
        "        ]\n",
        "\n",
        "        summaries = [task.result() for task in tasks]\n",
        "\n",
        "    return summaries\n",
        "\n",
        "# Example usage with error handling\n",
        "video_uri = \"gs://mrc-quant-ml-video-analysis/videoplayback.mp4\"\n",
        "\n",
        "try:\n",
        "    summary = summarize_video_chunk(\n",
        "        video_uri=video_uri,\n",
        "        start_offset=\"1s\",\n",
        "        end_offset=\"150s\",\n",
        "        prompt=\"Extract key technical concepts and timestamps. Focus on actionable insights.\"\n",
        "    )\n",
        "    print(summary)\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")\n",
        "    # Fallback to shorter chunk\n",
        "    summary = summarize_video_chunk(video_uri, \"1s\", \"60s\")\n",
        "    print(summary)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are key moments and technical concepts covered in the video:\n",
            "\n",
            "1. **Testing Live Streams (0:00-0:51):**\n",
            "   -  The streamer tests the live stream capability on YouTube and X (formerly Twitter). \n",
            "   -  They discuss if the live stream is working correctly on each platform.\n",
            "\n",
            "2. **Live Stream Introduction and Thumbnail Discussion (1:00-2:00):**\n",
            "   - The streamer transitions to introducing the topic of the stream, “Diffusion vs. Autoregressive”.\n",
            "   -  They note that the video’s thumbnail was AI-generated using Open AI’s GPT image generator but it misspelled the word autoregressive.\n",
            "\n",
            "3. **Topic: Diffusion Beats Autoregressive in Data-Constrained Settings (2:00-2:24):**\n",
            "    - The streamer reveals that they will be discussing a research paper that compares diffusion and autoregressive models in data-constrained environments, coming from Carnegie Mellon University.\n",
            "    -  They mention a video on the topic from “Three Blue One Brown.”\n",
            "\n",
            "4. **Referencing an External Video (2:25-2:31):**\n",
            "   - The streamer notes that they had the video by \"Three Blue One Brown\" pulled up, suggesting they’re ready to discuss it.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NSeNzLigYHV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g5GEZqTvWfvb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}