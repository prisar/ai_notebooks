{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNo5Up8iIpxaBSLdhVQpT+9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prisar/ai_notebooks/blob/main/nb_069.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DFEaiUj7gG0x"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "644660b8"
      },
      "source": [
        "# Task\n",
        "Write a Python script that demonstrates how to use AlphaFold to predict the structure of a protein. The script should:\n",
        "\n",
        "1. Install all necessary dependencies.\n",
        "2. Download the pre-trained AlphaFold model parameters.\n",
        "3. Define a protein sequence to be folded.\n",
        "4. Run the AlphaFold model to predict the protein's structure.\n",
        "5. Visualize the predicted 3D structure.\n",
        "6. Provide a way to download the predicted structure as a PDB file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9e3b795"
      },
      "source": [
        "## Install dependencies\n",
        "\n",
        "### Subtask:\n",
        "Install the necessary libraries, including `biopython` and the AlphaFold code from DeepMind.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bf46379a"
      },
      "source": [
        "**Reasoning**:\n",
        "The first step is to install the necessary libraries, so I will use `pip` to install `biopython` and AlphaFold.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41652152",
        "outputId": "230df15d-293e-4460-e092-8c446d4cfc1e"
      },
      "source": [
        "!pip install biopython\n",
        "!pip install git+https://github.com/deepmind/alphafold.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting biopython\n",
            "  Downloading biopython-1.85-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from biopython) (2.0.2)\n",
            "Downloading biopython-1.85-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: biopython\n",
            "Successfully installed biopython-1.85\n",
            "Collecting git+https://github.com/deepmind/alphafold.git\n",
            "  Cloning https://github.com/deepmind/alphafold.git to /tmp/pip-req-build-wh4ajjys\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/deepmind/alphafold.git /tmp/pip-req-build-wh4ajjys\n",
            "  Resolved https://github.com/deepmind/alphafold.git to commit e9b68483fc8764e7a1906e74a5d1f0ea2137311d\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from alphafold==2.3.2) (1.4.0)\n",
            "Requirement already satisfied: biopython in /usr/local/lib/python3.11/dist-packages (from alphafold==2.3.2) (1.85)\n",
            "Requirement already satisfied: chex in /usr/local/lib/python3.11/dist-packages (from alphafold==2.3.2) (0.1.89)\n",
            "Collecting dm-haiku (from alphafold==2.3.2)\n",
            "  Downloading dm_haiku-0.0.14-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.11/dist-packages (from alphafold==2.3.2) (0.1.9)\n",
            "Collecting docker (from alphafold==2.3.2)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: immutabledict in /usr/local/lib/python3.11/dist-packages (from alphafold==2.3.2) (4.2.1)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.11/dist-packages (from alphafold==2.3.2) (0.5.2)\n",
            "Collecting ml-collections (from alphafold==2.3.2)\n",
            "  Downloading ml_collections-1.1.0-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from alphafold==2.3.2) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from alphafold==2.3.2) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from alphafold==2.3.2) (1.16.0)\n",
            "Collecting tensorflow-cpu (from alphafold==2.3.2)\n",
            "  Downloading tensorflow_cpu-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from chex->alphafold==2.3.2) (4.14.1)\n",
            "Requirement already satisfied: jaxlib>=0.4.27 in /usr/local/lib/python3.11/dist-packages (from chex->alphafold==2.3.2) (0.5.1)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chex->alphafold==2.3.2) (0.12.1)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from jax->alphafold==2.3.2) (0.4.1)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.11/dist-packages (from jax->alphafold==2.3.2) (3.4.0)\n",
            "Collecting jmp>=0.0.2 (from dm-haiku->alphafold==2.3.2)\n",
            "  Downloading jmp-0.0.4-py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from dm-haiku->alphafold==2.3.2) (0.9.0)\n",
            "Requirement already satisfied: attrs>=18.2.0 in /usr/local/lib/python3.11/dist-packages (from dm-tree->alphafold==2.3.2) (25.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.11/dist-packages (from dm-tree->alphafold==2.3.2) (1.17.2)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from docker->alphafold==2.3.2) (2.32.3)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from docker->alphafold==2.3.2) (2.5.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from ml-collections->alphafold==2.3.2) (6.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->alphafold==2.3.2) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->alphafold==2.3.2) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->alphafold==2.3.2) (2025.2)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-cpu->alphafold==2.3.2) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow-cpu->alphafold==2.3.2) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow-cpu->alphafold==2.3.2) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow-cpu->alphafold==2.3.2) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-cpu->alphafold==2.3.2) (18.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow-cpu->alphafold==2.3.2) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow-cpu->alphafold==2.3.2) (5.29.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow-cpu->alphafold==2.3.2) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-cpu->alphafold==2.3.2) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-cpu->alphafold==2.3.2) (3.1.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow-cpu->alphafold==2.3.2) (1.73.1)\n",
            "Collecting tensorboard~=2.19.0 (from tensorflow-cpu->alphafold==2.3.2)\n",
            "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-cpu->alphafold==2.3.2) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-cpu->alphafold==2.3.2) (3.14.0)\n",
            "Collecting ml_dtypes>=0.4.0 (from jax->alphafold==2.3.2)\n",
            "  Downloading ml_dtypes-0.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow-cpu->alphafold==2.3.2) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow-cpu->alphafold==2.3.2) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow-cpu->alphafold==2.3.2) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow-cpu->alphafold==2.3.2) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow-cpu->alphafold==2.3.2) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->docker->alphafold==2.3.2) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->docker->alphafold==2.3.2) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->docker->alphafold==2.3.2) (2025.7.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow-cpu->alphafold==2.3.2) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow-cpu->alphafold==2.3.2) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow-cpu->alphafold==2.3.2) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow-cpu->alphafold==2.3.2) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow-cpu->alphafold==2.3.2) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow-cpu->alphafold==2.3.2) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-cpu->alphafold==2.3.2) (0.1.2)\n",
            "Downloading dm_haiku-0.0.14-py3-none-any.whl (373 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m373.8/373.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_collections-1.1.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.7/76.7 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_cpu-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (251.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.8/251.8 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmp-0.0.4-py3-none-any.whl (18 kB)\n",
            "Downloading ml_dtypes-0.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m74.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: alphafold\n",
            "  Building wheel for alphafold (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for alphafold: filename=alphafold-2.3.2-py3-none-any.whl size=251966 sha256=bbe0dbf44a63ef78416ea6f54598befb52be7f99658ee61131220740975b033a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-gl1aczkm/wheels/85/aa/59/b740813f272f1959d054d0cabfbbc77bfb03b0c951563a0236\n",
            "Successfully built alphafold\n",
            "Installing collected packages: ml_dtypes, ml-collections, jmp, tensorboard, docker, dm-haiku, tensorflow-cpu, alphafold\n",
            "  Attempting uninstall: ml_dtypes\n",
            "    Found existing installation: ml-dtypes 0.4.1\n",
            "    Uninstalling ml-dtypes-0.4.1:\n",
            "      Successfully uninstalled ml-dtypes-0.4.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.18.0\n",
            "    Uninstalling tensorboard-2.18.0:\n",
            "      Successfully uninstalled tensorboard-2.18.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.18.0 requires ml-dtypes<0.5.0,>=0.4.0, but you have ml-dtypes 0.5.1 which is incompatible.\n",
            "tensorflow 2.18.0 requires tensorboard<2.19,>=2.18, but you have tensorboard 2.19.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed alphafold-2.3.2 dm-haiku-0.0.14 docker-7.1.0 jmp-0.0.4 ml-collections-1.1.0 ml_dtypes-0.5.1 tensorboard-2.19.0 tensorflow-cpu-2.19.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "521dde7e"
      },
      "source": [
        "## Download model parameters\n",
        "\n",
        "### Subtask:\n",
        "Download the pre-trained AlphaFold model parameters.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fffc637"
      },
      "source": [
        "**Reasoning**:\n",
        "To download the AlphaFold parameters, I will use the `os.system` command to execute a `wget` command that downloads and extracts the pre-trained model parameters, as specified in the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7606f3b6",
        "outputId": "218d3a78-ff61-454c-91ea-7734aa933082"
      },
      "source": [
        "import os\n",
        "\n",
        "os.system(\"wget -q https://storage.googleapis.com/alphafold/alphafold_params_2022-03-02.tar && tar -xf alphafold_params_2022-03-02.tar && rm alphafold_params_2022-03-02.tar\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d815f486"
      },
      "source": [
        "## Define the protein sequence\n",
        "\n",
        "### Subtask:\n",
        "Define the protein sequence to be folded.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "858a4a7c"
      },
      "source": [
        "**Reasoning**:\n",
        "I will define the protein sequence as a string variable and then print it to the console to verify that it's correctly defined. This follows the instructions of the subtask.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88f9c742",
        "outputId": "575c9793-6b80-4f3d-cce3-8ba748b2f317"
      },
      "source": [
        "sequence = \"PIAQIHILEGRSDEQKETLIREVSEAISRSLDAPLTSVRVIITEMAKGHFGIGGELASK\"\n",
        "print(sequence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PIAQIHILEGRSDEQKETLIREVSEAISRSLDAPLTSVRVIITEMAKGHFGIGGELASK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1b15671"
      },
      "source": [
        "## Run alphafold\n",
        "\n",
        "### Subtask:\n",
        "Run the AlphaFold model to predict the protein structure. This will involve several steps, including feature extraction, model inference, and structure refinement.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbb21cf0"
      },
      "source": [
        "**Reasoning**:\n",
        "To run the AlphaFold model, I need to import the necessary modules, set up the model configuration, process the input sequence into features, and then run the model to get the unrelaxed protein structure.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "2511d084",
        "outputId": "102f7fff-0478-4629-ea40-b62146ff7acd"
      },
      "source": [
        "from alphafold.model import model, data\n",
        "from alphafold.common import protein\n",
        "from alphafold.model import config\n",
        "import numpy as np\n",
        "\n",
        "model_name = \"model_1\"\n",
        "model_config = config.model_config(model_name)\n",
        "model_config.data.eval.num_ensemble = 1\n",
        "model_params = data.get_model_haiku_params(model_name=model_name, data_dir='.')\n",
        "model_runner = model.RunModel(model_config, model_params)\n",
        "feature_dict = {\n",
        "    'aatype': np.array([protein.restype_order[res] for res in sequence]),\n",
        "    'between_segment_residues': np.zeros((len(sequence),), dtype=np.int32),\n",
        "    'domain_name': 'test',\n",
        "    'residue_index': np.arange(len(sequence), dtype=np.int32),\n",
        "    'seq_length': np.array([len(sequence)], dtype=np.int32),\n",
        "    'sequence': np.array([sequence.encode('utf-8')], dtype=np.object_),\n",
        "}\n",
        "prediction_result = model_runner.predict(feature_dict)\n",
        "unrelaxed_protein = protein.from_prediction(\n",
        "    features=feature_dict,\n",
        "    result=prediction_result,\n",
        "    b_factors=prediction_result['plddt'],\n",
        "    remove_leading_feature_dimension=True)\n",
        "\n",
        "print(\"Unrelaxed protein structure obtained.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: './params/params_model_1.npz'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4-3538544065.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_ensemble\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model_haiku_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mmodel_runner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRunModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m feature_dict = {\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/alphafold/model/data.py\u001b[0m in \u001b[0;36mget_model_haiku_params\u001b[0;34m(model_name, data_dir)\u001b[0m\n\u001b[1;32m     28\u001b[0m   \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'params'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'params_{model_name}.npz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m   \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './params/params_model_1.npz'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49bdfe5c"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous attempt failed because the model parameters were not found in the expected directory. The `data_dir` should point to the directory where the `params` folder is located. The previous subtask extracted the parameters to the root directory, so I need to change `data_dir` to point to the correct location, which is the parent directory of the `params` folder.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "NWajXM_UL3RQ",
        "outputId": "9b65903e-36f4-4b32-e682-577c1b4ee271"
      },
      "source": [
        "from alphafold.model import model, data\n",
        "from alphafold.common import protein\n",
        "from alphafold.model import config\n",
        "import numpy as np\n",
        "\n",
        "model_name = \"model_1\"\n",
        "model_config = config.model_config(model_name)\n",
        "model_config.data.eval.num_ensemble = 1\n",
        "# The parameters are in the root directory, so data_dir should be '.'\n",
        "model_params = data.get_model_haiku_params(model_name=model_name, data_dir='.')\n",
        "model_runner = model.RunModel(model_config, model_params)\n",
        "feature_dict = {\n",
        "    'aatype': np.array([protein.restype_order[res] for res in sequence]),\n",
        "    'between_segment_residues': np.zeros((len(sequence),), dtype=np.int32),\n",
        "    'domain_name': 'test',\n",
        "    'residue_index': np.arange(len(sequence), dtype=np.int32),\n",
        "    'seq_length': np.array([len(sequence)], dtype=np.int32),\n",
        "    'sequence': np.array([sequence.encode('utf-8')], dtype=np.object_),\n",
        "}\n",
        "prediction_result = model_runner.predict(feature_dict)\n",
        "unrelaxed_protein = protein.from_prediction(\n",
        "    features=feature_dict,\n",
        "    result=prediction_result,\n",
        "    b_factors=prediction_result['plddt'],\n",
        "    remove_leading_feature_dimension=True)\n",
        "\n",
        "print(\"Unrelaxed protein structure obtained.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: './params/params_model_1.npz'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-5-2073732947.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_ensemble\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# The parameters are in the root directory, so data_dir should be '.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmodel_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model_haiku_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mmodel_runner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRunModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m feature_dict = {\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/alphafold/model/data.py\u001b[0m in \u001b[0;36mget_model_haiku_params\u001b[0;34m(model_name, data_dir)\u001b[0m\n\u001b[1;32m     28\u001b[0m   \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'params'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'params_{model_name}.npz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m   \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './params/params_model_1.npz'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d4e6a5b"
      },
      "source": [
        "**Reasoning**:\n",
        "The error persists because the `get_model_haiku_params` function expects the `data_dir` to contain the `params` directory. The parameters were extracted into a directory called `params` in the current working directory. I will set the `data_dir` to point to the parent directory of the `params` directory, which is the current working directory. I will also add a check to see if the file exists before trying to open it.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "bOkeyrY4MBot",
        "outputId": "b8ac521b-5b5c-4c6a-e699-9838a969d36a"
      },
      "source": [
        "from alphafold.model import model, data\n",
        "from alphafold.common import protein\n",
        "from alphafold.model import config\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "model_name = \"model_1\"\n",
        "model_config = config.model_config(model_name)\n",
        "model_config.data.eval.num_ensemble = 1\n",
        "\n",
        "# The parameters are in the `params` directory in the current working directory.\n",
        "data_dir = '.'\n",
        "params_path = os.path.join(data_dir, 'params', f'params_{model_name}.npz')\n",
        "\n",
        "if not os.path.exists(params_path):\n",
        "    print(f\"Error: Could not find model parameters at {params_path}\")\n",
        "    # As a fallback, try to locate them in the alphafold installation directory\n",
        "    try:\n",
        "        import alphafold\n",
        "        alphafold_dir = os.path.dirname(alphafold.__file__)\n",
        "        data_dir = os.path.join(alphafold_dir, '..')\n",
        "        params_path = os.path.join(data_dir, 'params', f'params_{model_name}.npz')\n",
        "        if not os.path.exists(params_path):\n",
        "            raise FileNotFoundError\n",
        "    except (ImportError, FileNotFoundError):\n",
        "        print(\"Could not find alphafold installation directory. Please ensure the parameters are in the correct location.\")\n",
        "\n",
        "\n",
        "model_params = data.get_model_haiku_params(model_name=model_name, data_dir=data_dir)\n",
        "model_runner = model.RunModel(model_config, model_params)\n",
        "feature_dict = {\n",
        "    'aatype': np.array([protein.restype_order[res] for res in sequence]),\n",
        "    'between_segment_residues': np.zeros((len(sequence),), dtype=np.int32),\n",
        "    'domain_name': 'test',\n",
        "    'residue_index': np.arange(len(sequence), dtype=np.int32),\n",
        "    'seq_length': np.array([len(sequence)], dtype=np.int32),\n",
        "    'sequence': np.array([sequence.encode('utf-8')], dtype=np.object_),\n",
        "}\n",
        "prediction_result = model_runner.predict(feature_dict)\n",
        "unrelaxed_protein = protein.from_prediction(\n",
        "    features=feature_dict,\n",
        "    result=prediction_result,\n",
        "    b_factors=prediction_result['plddt'],\n",
        "    remove_leading_feature_dimension=True)\n",
        "\n",
        "print(\"Unrelaxed protein structure obtained.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: Could not find model parameters at ./params/params_model_1.npz\n",
            "Could not find alphafold installation directory. Please ensure the parameters are in the correct location.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/usr/local/lib/python3.11/dist-packages/alphafold/../params/params_model_1.npz'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-6-2556546109.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mmodel_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model_haiku_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0mmodel_runner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRunModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m feature_dict = {\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/alphafold/model/data.py\u001b[0m in \u001b[0;36mget_model_haiku_params\u001b[0;34m(model_name, data_dir)\u001b[0m\n\u001b[1;32m     28\u001b[0m   \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'params'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'params_{model_name}.npz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m   \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/usr/local/lib/python3.11/dist-packages/alphafold/../params/params_model_1.npz'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cb087222"
      },
      "source": [
        "**Reasoning**:\n",
        "The issue is that the `data_dir` is not being set correctly. It seems the parameters are in the `alphafold_params` directory. I'll correct the path to the parameters and try again.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "id": "XnPAh51qMGpj",
        "outputId": "d9d9ae3d-ed3a-447c-ae33-a23be0420639"
      },
      "source": [
        "from alphafold.model import model, data\n",
        "from alphafold.common import protein\n",
        "from alphafold.model import config\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "model_name = \"model_1\"\n",
        "model_config = config.model_config(model_name)\n",
        "model_config.data.eval.num_ensemble = 1\n",
        "\n",
        "# The parameters are in the `alphafold_params` directory\n",
        "data_dir = './alphafold_params'\n",
        "\n",
        "model_params = data.get_model_haiku_params(model_name=model_name, data_dir=data_dir)\n",
        "model_runner = model.RunModel(model_config, model_params)\n",
        "\n",
        "# Re-create the feature_dict as it's not in the current scope\n",
        "feature_dict = {\n",
        "    'aatype': np.array([protein.restype_order[res] for res in sequence]),\n",
        "    'between_segment_residues': np.zeros((len(sequence),), dtype=np.int32),\n",
        "    'domain_name': 'test',\n",
        "    'residue_index': np.arange(len(sequence), dtype=np.int32),\n",
        "    'seq_length': np.array([len(sequence)], dtype=np.int32),\n",
        "    'sequence': np.array([sequence.encode('utf-8')], dtype=np.object_),\n",
        "}\n",
        "\n",
        "\n",
        "prediction_result = model_runner.predict(feature_dict)\n",
        "unrelaxed_protein = protein.from_prediction(\n",
        "    features=feature_dict,\n",
        "    result=prediction_result,\n",
        "    b_factors=prediction_result['plddt'],\n",
        "    remove_leading_feature_dimension=True)\n",
        "\n",
        "print(\"Unrelaxed protein structure obtained.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: './alphafold_params/params/params_model_1.npz'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-7-3647903976.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mdata_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./alphafold_params'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmodel_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model_haiku_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mmodel_runner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRunModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/alphafold/model/data.py\u001b[0m in \u001b[0;36mget_model_haiku_params\u001b[0;34m(model_name, data_dir)\u001b[0m\n\u001b[1;32m     28\u001b[0m   \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'params'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'params_{model_name}.npz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m   \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './alphafold_params/params/params_model_1.npz'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3a0867d4"
      },
      "source": [
        "**Reasoning**:\n",
        "The error indicates that the path to the parameters is still incorrect. The `get_model_haiku_params` function is looking for a `params` directory inside the `data_dir`. The parameters are located directly in the `alphafold_params` directory. The correct approach is to set `data_dir` to the parent directory of `alphafold_params`, which is the current directory, and then the function will correctly construct the path as `./alphafold_params/params_model_1.npz`. However, the function is hardcoded to look for a `params` subdirectory. I will therefore move the downloaded parameters into a `params` directory.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "sEWRwIzYMNQE",
        "outputId": "86941f52-3205-41f2-b39c-de5f12686380"
      },
      "source": [
        "import os\n",
        "os.makedirs('params', exist_ok=True)\n",
        "os.system('mv ./alphafold_params/* ./params/')\n",
        "from alphafold.model import model, data\n",
        "from alphafold.common import protein\n",
        "from alphafold.model import config\n",
        "import numpy as np\n",
        "\n",
        "model_name = \"model_1\"\n",
        "model_config = config.model_config(model_name)\n",
        "model_config.data.eval.num_ensemble = 1\n",
        "\n",
        "data_dir = '.'\n",
        "\n",
        "model_params = data.get_model_haiku_params(model_name=model_name, data_dir=data_dir)\n",
        "model_runner = model.RunModel(model_config, model_params)\n",
        "\n",
        "# Re-create the feature_dict as it's not in the current scope\n",
        "feature_dict = {\n",
        "    'aatype': np.array([protein.restype_order[res] for res in sequence]),\n",
        "    'between_segment_residues': np.zeros((len(sequence),), dtype=np.int32),\n",
        "    'domain_name': 'test',\n",
        "    'residue_index': np.arange(len(sequence), dtype=np.int32),\n",
        "    'seq_length': np.array([len(sequence)], dtype=np.int32),\n",
        "    'sequence': np.array([sequence.encode('utf-8')], dtype=np.object_),\n",
        "}\n",
        "\n",
        "\n",
        "prediction_result = model_runner.predict(feature_dict)\n",
        "unrelaxed_protein = protein.from_prediction(\n",
        "    features=feature_dict,\n",
        "    result=prediction_result,\n",
        "    b_factors=prediction_result['plddt'],\n",
        "    remove_leading_feature_dimension=True)\n",
        "\n",
        "print(\"Unrelaxed protein structure obtained.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: './params/params_model_1.npz'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-8-92305632.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mdata_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mmodel_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model_haiku_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mmodel_runner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRunModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/alphafold/model/data.py\u001b[0m in \u001b[0;36mget_model_haiku_params\u001b[0;34m(model_name, data_dir)\u001b[0m\n\u001b[1;32m     28\u001b[0m   \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'params'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'params_{model_name}.npz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m   \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './params/params_model_1.npz'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ec023602"
      },
      "source": [
        "## Run alphafold\n",
        "\n",
        "### Subtask:\n",
        "Run the AlphaFold model to predict the protein structure. This will involve several steps, including feature extraction, model inference, and structure refinement.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ba4a96fa"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous attempt to run the AlphaFold model failed because the model parameters could not be loaded. Although the previous attempt tried to move the parameters to a 'params' directory, it seems the `data.get_model_haiku_params` function might be looking for the parameters in a different location or the previous move command failed silently. This time, I will explicitly ensure the 'params' directory exists and the model parameter file is present before attempting to load the parameters. I will then re-attempt the rest of the steps as per the instructions: import necessary modules, define model configuration, load parameters, create model runner, recreate feature dict, run prediction, and convert to unrelaxed protein structure.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4d253203",
        "outputId": "20aaaa60-fa78-471a-99a3-e30b465e6b6f"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Ensure the 'params' directory exists and contains the parameter file\n",
        "params_dir = './params'\n",
        "model_param_file = os.path.join(params_dir, 'params_model_1.npz')\n",
        "\n",
        "# Create the 'params' directory if it doesn't exist\n",
        "os.makedirs(params_dir, exist_ok=True)\n",
        "\n",
        "# Check if the parameter file is in the current directory from the extraction\n",
        "extracted_param_file = './alphafold_params/params_model_1.npz'\n",
        "\n",
        "if os.path.exists(extracted_param_file):\n",
        "    print(f\"Found {extracted_param_file}. Moving to {params_dir}.\")\n",
        "    # Move the parameter file to the 'params' directory\n",
        "    shutil.move(extracted_param_file, params_dir)\n",
        "elif not os.path.exists(model_param_file):\n",
        "    print(f\"Error: {model_param_file} not found after trying to move. Please ensure the parameter file is in the './alphafold_params' directory before running.\")\n",
        "else:\n",
        "    print(f\"{model_param_file} already exists.\")\n",
        "\n",
        "\n",
        "from alphafold.model import model, data\n",
        "from alphafold.common import protein\n",
        "from alphafold.model import config\n",
        "import numpy as np\n",
        "\n",
        "model_name = \"model_1\"\n",
        "model_config = config.model_config(model_name)\n",
        "model_config.data.eval.num_ensemble = 1\n",
        "\n",
        "data_dir = '.' # This should now correctly point to the directory containing the 'params' subdirectory\n",
        "\n",
        "try:\n",
        "    model_params = data.get_model_haiku_params(model_name=model_name, data_dir=data_dir)\n",
        "    print(\"Model parameters loaded successfully.\")\n",
        "\n",
        "    model_runner = model.RunModel(model_config, model_params)\n",
        "    print(\"Model runner created.\")\n",
        "\n",
        "    # Re-create the feature_dict based on the sequence variable\n",
        "    # Ensure sequence variable is defined. Assuming it's defined in a previous cell.\n",
        "    # sequence = \"PIAQIHILEGRSDEQKETLIREVSEAISRSLDAPLTSVRVIITEMAKGHFGIGGELASK\" # Uncomment if sequence is not in scope\n",
        "\n",
        "    feature_dict = {\n",
        "        'aatype': np.array([protein.restype_order.get(res, 20) for res in sequence]), # Use .get() with default for safety\n",
        "        'between_segment_residues': np.zeros((len(sequence),), dtype=np.int32),\n",
        "        'domain_name': np.array([b'test'], dtype=np.object_), # domain_name should be a numpy array of bytes\n",
        "        'residue_index': np.arange(len(sequence), dtype=np.int32),\n",
        "        'seq_length': np.array([len(sequence)], dtype=np.int32),\n",
        "        'sequence': np.array([sequence.encode('utf-8')], dtype=np.object_),\n",
        "    }\n",
        "    print(\"Feature dictionary created.\")\n",
        "\n",
        "\n",
        "    prediction_result = model_runner.predict(feature_dict)\n",
        "    print(\"Prediction completed.\")\n",
        "\n",
        "    unrelaxed_protein = protein.from_prediction(\n",
        "        features=feature_dict,\n",
        "        result=prediction_result,\n",
        "        b_factors=prediction_result['plddt'],\n",
        "        remove_leading_feature_dimension=True)\n",
        "\n",
        "    print(\"Unrelaxed protein structure obtained.\")\n",
        "\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"Error loading model parameters: {e}\")\n",
        "    print(\"Please ensure the 'params' directory exists and contains 'params_model_1.npz'.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during prediction: {e}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: ./params/params_model_1.npz not found after trying to move. Please ensure the parameter file is in the './alphafold_params' directory before running.\n",
            "Error loading model parameters: [Errno 2] No such file or directory: './params/params_model_1.npz'\n",
            "Please ensure the 'params' directory exists and contains 'params_model_1.npz'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6b1ea325"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous attempt failed because the parameter file `params_model_1.npz` was not found in the expected location (`./alphafold_params/`), even though the download and extraction in the second subtask was reported as successful. It's possible that the extracted files are in a different subdirectory within `alphafold_params`. I will now list the contents of the `alphafold_params` directory to diagnose the problem and see where the parameter files are actually located. This will help in formulating the correct file path for the next attempt.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dad59942",
        "outputId": "051d6fe2-6c2c-404b-f175-bacf75bd6014"
      },
      "source": [
        "!ls -R ./alphafold_params"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access './alphafold_params': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a003270c"
      },
      "source": [
        "**Reasoning**:\n",
        "The `ls` command failed, indicating that the `alphafold_params` directory does not exist in the current working directory. This contradicts the successful completion of the second subtask, which was supposed to download and extract these parameters. It's likely that the execution environment was reset or the files were not persisted between subtasks. Therefore, I need to re-run the download and extraction process from subtask 2 to make the parameter files available. After re-downloading, I will proceed with moving the parameters and running the model as originally planned.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d84b9e4c",
        "outputId": "9d0c484c-86bc-42bc-825e-ef33858ec8b5"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Re-run the download and extraction from subtask 2\n",
        "print(\"Downloading and extracting AlphaFold parameters...\")\n",
        "os.system(\"wget -q https://storage.googleapis.com/alphafold/alphafold_params_2022-03-02.tar && tar -xf alphafold_params_2022-03-02.tar && rm alphafold_params_2022-03-02.tar\")\n",
        "print(\"Download and extraction complete.\")\n",
        "\n",
        "# Now, proceed with the original plan for this subtask\n",
        "params_dir = './params'\n",
        "model_param_file = os.path.join(params_dir, 'params_model_1.npz')\n",
        "\n",
        "os.makedirs(params_dir, exist_ok=True)\n",
        "\n",
        "# The parameters are inside 'alphafold_params_2022-03-02' after extraction\n",
        "source_param_dir = './alphafold_params'\n",
        "\n",
        "# Move all .npz files from the source to the target 'params' directory\n",
        "if os.path.exists(source_param_dir):\n",
        "    for item in os.listdir(source_param_dir):\n",
        "        if item.endswith(\".npz\"):\n",
        "            shutil.move(os.path.join(source_param_dir, item), params_dir)\n",
        "    print(f\"Moved parameter files from {source_param_dir} to {params_dir}.\")\n",
        "else:\n",
        "    print(f\"Error: The directory '{source_param_dir}' was not created after extraction.\")\n",
        "\n",
        "\n",
        "from alphafold.model import model, data\n",
        "from alphafold.common import protein\n",
        "from alphafold.model import config\n",
        "import numpy as np\n",
        "\n",
        "model_name = \"model_1\"\n",
        "model_config = config.model_config(model_name)\n",
        "model_config.data.eval.num_ensemble = 1\n",
        "\n",
        "data_dir = '.'\n",
        "\n",
        "try:\n",
        "    model_params = data.get_model_haiku_params(model_name=model_name, data_dir=data_dir)\n",
        "    print(\"Model parameters loaded successfully.\")\n",
        "\n",
        "    model_runner = model.RunModel(model_config, model_params)\n",
        "    print(\"Model runner created.\")\n",
        "\n",
        "    # Assuming 'sequence' variable is available from a previous cell\n",
        "    # sequence = \"PIAQIHILEGRSDEQKETLIREVSEAISRSLDAPLTSVRVIITEMAKGHFGIGGELASK\"\n",
        "\n",
        "    feature_dict = {\n",
        "        'aatype': np.array([protein.restype_order.get(res, 20) for res in sequence]),\n",
        "        'between_segment_residues': np.zeros((len(sequence),), dtype=np.int32),\n",
        "        'domain_name': np.array([b'test'], dtype=np.object_),\n",
        "        'residue_index': np.arange(len(sequence), dtype=np.int32),\n",
        "        'seq_length': np.array([len(sequence)], dtype=np.int32),\n",
        "        'sequence': np.array([sequence.encode('utf-8')], dtype=np.object_),\n",
        "    }\n",
        "    print(\"Feature dictionary created.\")\n",
        "\n",
        "    prediction_result = model_runner.predict(feature_dict)\n",
        "    print(\"Prediction completed.\")\n",
        "\n",
        "    unrelaxed_protein = protein.from_prediction(\n",
        "        features=feature_dict,\n",
        "        result=prediction_result,\n",
        "        b_factors=prediction_result['plddt'],\n",
        "        remove_leading_feature_dimension=True)\n",
        "\n",
        "    print(\"Unrelaxed protein structure obtained.\")\n",
        "\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"Error loading model parameters: {e}\")\n",
        "    print(\"Please ensure the 'params' directory exists and contains the necessary parameter files.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and extracting AlphaFold parameters...\n",
            "Download and extraction complete.\n",
            "Error: The directory './alphafold_params' was not created after extraction.\n",
            "Error loading model parameters: [Errno 2] No such file or directory: './params/params_model_1.npz'\n",
            "Please ensure the 'params' directory exists and contains the necessary parameter files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15aa37e3"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous attempt failed again because the `alphafold_params` directory was not found after the download and extraction step. The `tar` command might be extracting the contents into a directory with a different name. I will first re-run the download and extraction, and then I will use `ls -l` to inspect the current directory's contents to see the exact name of the directory created by the `tar` command. This will allow me to finally provide the correct path to the parameter files.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv *.npz params"
      ],
      "metadata": {
        "id": "LN95qk0PNy7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "id": "53c3b8bf",
        "outputId": "d160a630-779f-475a-b210-fa52c258b8bd"
      },
      "source": [
        "from alphafold.model import model, data\n",
        "from alphafold.common import protein\n",
        "from alphafold.model import config\n",
        "import numpy as np\n",
        "\n",
        "model_name = \"model_1\"\n",
        "model_config = config.model_config(model_name)\n",
        "model_config.data.eval.num_ensemble = 1\n",
        "model_params = data.get_model_haiku_params(model_name=model_name, data_dir='/content')\n",
        "model_runner = model.RunModel(model_config, model_params)\n",
        "feature_dict = {\n",
        "    'aatype': np.array([protein.restype_order[res] for res in sequence]),\n",
        "    'between_segment_residues': np.zeros((len(sequence),), dtype=np.int32),\n",
        "    'domain_name': 'test',\n",
        "    'residue_index': np.arange(len(sequence), dtype=np.int32),\n",
        "    'seq_length': np.array([len(sequence)], dtype=np.int32),\n",
        "    'sequence': np.array([sequence.encode('utf-8')], dtype=np.object_),\n",
        "}\n",
        "prediction_result = model_runner.predict(feature_dict)\n",
        "unrelaxed_protein = protein.from_prediction(\n",
        "    features=feature_dict,\n",
        "    result=prediction_result,\n",
        "    b_factors=prediction_result['plddt'],\n",
        "    remove_leading_feature_dimension=True)\n",
        "\n",
        "print(\"Unrelaxed protein structure obtained.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'alphafold.common.protein' has no attribute 'restype_order'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-17-95888194.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmodel_runner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRunModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m feature_dict = {\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;34m'aatype'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprotein\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestype_order\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;34m'between_segment_residues'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;34m'domain_name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-17-95888194.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmodel_runner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRunModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m feature_dict = {\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;34m'aatype'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprotein\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestype_order\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;34m'between_segment_residues'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;34m'domain_name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'alphafold.common.protein' has no attribute 'restype_order'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43e2bc8c"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous execution failed with an `AttributeError: module 'alphafold.common.protein' has no attribute 'restype_order'`. This indicates that `restype_order` is not available in `alphafold.common.protein`. After inspecting the AlphaFold source code, it's clear that `restype_order` is located in `alphafold.common.residue_constants`. I need to import this module and use `residue_constants.restype_order` instead. I will also correct the `domain_name` to be a bytes-like object as required by the model. I will re-run the entire prediction process with these corrections. I will also re-download the parameters since the environment might have been reset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhJEHQljOCK2",
        "outputId": "2f150f9a-7c7d-4e62-bfc8-0789accd8fac"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "from alphafold.model import model, data, config\n",
        "from alphafold.common import protein, residue_constants\n",
        "\n",
        "# # Re-download and extract parameters to be safe\n",
        "# print(\"Downloading and extracting AlphaFold parameters...\")\n",
        "# os.system(\"wget -q https://storage.googleapis.com/alphafold/alphafold_params_2022-03-02.tar && tar -xf alphafold_params_2022-03-02.tar && rm alphafold_params_2022-03-02.tar\")\n",
        "# print(\"Download and extraction complete.\")\n",
        "\n",
        "params_dir = './params'\n",
        "os.makedirs(params_dir, exist_ok=True)\n",
        "source_param_dir = './alphafold_params'\n",
        "\n",
        "# if os.path.exists(source_param_dir):\n",
        "#     for item in os.listdir(source_param_dir):\n",
        "#         if item.endswith(\".npz\"):\n",
        "#             shutil.move(os.path.join(source_param_dir, item), params_dir)\n",
        "#     print(f\"Moved parameter files from {source_param_dir} to {params_dir}.\")\n",
        "# else:\n",
        "#     print(f\"Error: The directory '{source_param_dir}' was not created after extraction.\")\n",
        "\n",
        "model_name = \"model_1\"\n",
        "model_config = config.model_config(model_name)\n",
        "model_config.data.eval.num_ensemble = 1\n",
        "data_dir = '/content'\n",
        "\n",
        "try:\n",
        "    model_params = data.get_model_haiku_params(model_name=model_name, data_dir=data_dir)\n",
        "    print(\"Model parameters loaded successfully.\")\n",
        "\n",
        "    model_runner = model.RunModel(model_config, model_params)\n",
        "    print(\"Model runner created.\")\n",
        "\n",
        "    # Correctly create the feature_dict\n",
        "    feature_dict = {\n",
        "        'aatype': np.array([residue_constants.restype_order.get(res, residue_constants.restype_num) for res in sequence]),\n",
        "        'between_segment_residues': np.zeros((len(sequence),), dtype=np.int32),\n",
        "        'domain_name': np.array([b'test'], dtype=np.object_),\n",
        "        'residue_index': np.arange(len(sequence), dtype=np.int32),\n",
        "        'seq_length': np.array([len(sequence)], dtype=np.int32),\n",
        "        'sequence': np.array([sequence.encode('utf-8')], dtype=np.object_),\n",
        "    }\n",
        "    print(\"Feature dictionary created.\")\n",
        "\n",
        "    prediction_result = model_runner.predict(feature_dict)\n",
        "    print(\"Prediction completed.\")\n",
        "\n",
        "    unrelaxed_protein = protein.from_prediction(\n",
        "        features=feature_dict,\n",
        "        result=prediction_result,\n",
        "        b_factors=prediction_result['plddt'],\n",
        "        remove_leading_feature_dimension=True)\n",
        "\n",
        "    print(\"Unrelaxed protein structure obtained.\")\n",
        "\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"Error loading model parameters: {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model parameters loaded successfully.\n",
            "Model runner created.\n",
            "Feature dictionary created.\n",
            "An error occurred: RunModel.predict() missing 1 required positional argument: 'random_seed'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ec7b0791"
      },
      "source": [
        "**Reasoning**:\n",
        "The error message `RunModel.predict() missing 1 required positional argument: 'random_seed'` indicates that the `predict` method of the `RunModel` class requires a `random_seed` argument. I need to provide a random seed to the `predict` call. I will add a `random_seed` to the `model_runner.predict` call to fix this issue. I will use a fixed integer for reproducibility. I am not re-downloading the parameters this time as the previous step showed they were loaded successfully, and the error is in the `predict` call itself.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "6892d312",
        "outputId": "b9456877-6b91-461b-cbd8-3a50288916d7"
      },
      "source": [
        "import numpy as np\n",
        "from alphafold.model import model, data, config\n",
        "from alphafold.common import protein, residue_constants\n",
        "\n",
        "# It's safer to re-establish the model runner in case the environment was cleared,\n",
        "# but I will assume model_runner and feature_dict are still in memory from the previous attempt.\n",
        "# If this fails, the full script should be re-run.\n",
        "\n",
        "# Let's re-create the necessary components just in case, as the state might be lost.\n",
        "model_name = \"model_1\"\n",
        "data_dir = '/content'\n",
        "model_config = config.model_config(model_name)\n",
        "model_config.data.eval.num_ensemble = 1\n",
        "model_params = data.get_model_haiku_params(model_name=model_name, data_dir=data_dir)\n",
        "model_runner = model.RunModel(model_config, model_params)\n",
        "\n",
        "feature_dict = {\n",
        "    'aatype': np.array([residue_constants.restype_order.get(res, residue_constants.restype_num) for res in sequence]),\n",
        "    'between_segment_residues': np.zeros((len(sequence),), dtype=np.int32),\n",
        "    'domain_name': np.array([b'test'], dtype=np.object_),\n",
        "    'residue_index': np.arange(len(sequence), dtype=np.int32),\n",
        "    'seq_length': np.array([len(sequence)], dtype=np.int32),\n",
        "    'sequence': np.array([sequence.encode('utf-8')], dtype=np.object_),\n",
        "}\n",
        "\n",
        "\n",
        "# Provide a random seed to the predict method\n",
        "prediction_result = model_runner.predict(feature_dict, random_seed=0)\n",
        "\n",
        "unrelaxed_protein = protein.from_prediction(\n",
        "    features=feature_dict,\n",
        "    result=prediction_result,\n",
        "    b_factors=prediction_result['plddt'],\n",
        "    remove_leading_feature_dimension=True)\n",
        "\n",
        "print(\"Unrelaxed protein structure obtained.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Error interpreting argument to <function without_state.<locals>.apply_fn at 0x7c2b1831ab60> as an abstract array. The problematic value is of type <class 'numpy.ndarray'> and was passed to the function at path batch['domain_name'].\nThis typically means that a jit-wrapped function was called with a non-array argument, and this argument was not marked as static using the static_argnums or static_argnames parameters of jax.jit.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-22-1798015193.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Provide a random seed to the predict method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mprediction_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_runner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m unrelaxed_protein = protein.from_prediction(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/alphafold/model/model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, feat, random_seed)\u001b[0m\n\u001b[1;32m    165\u001b[0m     logging.info('Running predict with shape(feat) = %s',\n\u001b[1;32m    166\u001b[0m                  tree.map_structure(lambda x: x.shape, feat))\n\u001b[0;32m--> 167\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPRNGKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_seed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;31m# This block is to ensure benchmark timings are accurate. Some blocking is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "    \u001b[0;31m[... skipping hidden 4 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jax/_src/pjit.py\u001b[0m in \u001b[0;36m_infer_input_type\u001b[0;34m(fun, dbg, explicit_args)\u001b[0m\n\u001b[1;32m    749\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m     \u001b[0marg_description\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"path {dbg.arg_names[i]}\"\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m     raise TypeError(\n\u001b[0m\u001b[1;32m    752\u001b[0m       \u001b[0;34mf\"Error interpreting argument to {fun} as an abstract array.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m       \u001b[0;34mf\" The problematic value is of type {type(x)} and was passed to\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Error interpreting argument to <function without_state.<locals>.apply_fn at 0x7c2b1831ab60> as an abstract array. The problematic value is of type <class 'numpy.ndarray'> and was passed to the function at path batch['domain_name'].\nThis typically means that a jit-wrapped function was called with a non-array argument, and this argument was not marked as static using the static_argnums or static_argnames parameters of jax.jit."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1644beab"
      },
      "source": [
        "**Reasoning**:\n",
        "The error `TypeError: Error interpreting argument to <function without_state.<locals>.apply_fn ...> as an abstract array. The problematic value is of type <class 'numpy.ndarray'> and was passed to the function at path batch['domain_name'].` indicates that the `domain_name` in the feature dictionary is causing issues with JAX's just-in-time (JIT) compilation. The error message suggests that non-array arguments to a JIT-wrapped function should be marked as static. Looking at the AlphaFold code, the `domain_name` is indeed treated differently and should not be a NumPy array of objects. It should be a simple byte string. I will correct the `domain_name` entry in the `feature_dict` to be a byte string instead of a NumPy array and re-run the prediction.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "1WojYA4LPCBe",
        "outputId": "0c2a856e-36c3-40fb-9a7a-cc5efeadf4c8"
      },
      "source": [
        "import numpy as np\n",
        "from alphafold.model import model, data, config\n",
        "from alphafold.common import protein, residue_constants\n",
        "\n",
        "# Re-initialize the model runner and feature dictionary to ensure they are correctly configured.\n",
        "model_name = \"model_1\"\n",
        "data_dir = '/content'\n",
        "model_config = config.model_config(model_name)\n",
        "model_config.data.eval.num_ensemble = 1\n",
        "model_params = data.get_model_haiku_params(model_name=model_name, data_dir=data_dir)\n",
        "model_runner = model.RunModel(model_config, model_params)\n",
        "\n",
        "# Correct the domain_name to be a byte string, not a numpy array.\n",
        "feature_dict = {\n",
        "    'aatype': np.array([residue_constants.restype_order.get(res, residue_constants.restype_num) for res in sequence]),\n",
        "    'between_segment_residues': np.zeros((len(sequence),), dtype=np.int32),\n",
        "    'domain_name': b'test',  # Corrected: should be a byte string\n",
        "    'residue_index': np.arange(len(sequence), dtype=np.int32),\n",
        "    'seq_length': np.array([len(sequence)], dtype=np.int32),\n",
        "    'sequence': np.array([sequence.encode('utf-8')], dtype=np.object_),\n",
        "}\n",
        "\n",
        "# Provide a random seed to the predict method\n",
        "prediction_result = model_runner.predict(feature_dict, random_seed=0)\n",
        "\n",
        "unrelaxed_protein = protein.from_prediction(\n",
        "    features=feature_dict,\n",
        "    result=prediction_result,\n",
        "    b_factors=prediction_result['plddt'],\n",
        "    remove_leading_feature_dimension=True)\n",
        "\n",
        "print(\"Unrelaxed protein structure obtained.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'bytes' object has no attribute 'shape'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-24-115032822.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# Provide a random seed to the predict method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mprediction_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_runner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m unrelaxed_protein = protein.from_prediction(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/alphafold/model/model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, feat, random_seed)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     logging.info('Running predict with shape(feat) = %s',\n\u001b[0;32m--> 166\u001b[0;31m                  tree.map_structure(lambda x: x.shape, feat))\n\u001b[0m\u001b[1;32m    167\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPRNGKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_seed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tree/__init__.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structures, **kwargs)\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0massert_same_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m   return unflatten_as(structures[0],\n\u001b[0;32m--> 428\u001b[0;31m                       [func(*args) for args in zip(*map(flatten, structures))])\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tree/__init__.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0massert_same_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m   return unflatten_as(structures[0],\n\u001b[0;32m--> 428\u001b[0;31m                       [func(*args) for args in zip(*map(flatten, structures))])\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/alphafold/model/model.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     logging.info('Running predict with shape(feat) = %s',\n\u001b[0;32m--> 166\u001b[0;31m                  tree.map_structure(lambda x: x.shape, feat))\n\u001b[0m\u001b[1;32m    167\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPRNGKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_seed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'bytes' object has no attribute 'shape'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1c5930f"
      },
      "source": [
        "**Reasoning**:\n",
        "Reasoning: The error `AttributeError: 'bytes' object has no attribute 'shape'` occurs because the logging line `tree.map_structure(lambda x: x.shape, feat)` in the `predict` function tries to access the `.shape` attribute of every item in the `feature_dict`. While NumPy arrays have this attribute, a raw Python `bytes` object does not. This seems to be an issue with how the feature dictionary is processed before the actual prediction.\n",
        "\n",
        "Looking back at the initial `feature_dict` variable provided in the context, `domain_name` was `b'test'`. However, the error now suggests this is incorrect. Let's re-examine the `feature_dict` that was present in the initial context. The `domain_name` was `b'test'`, but let's try wrapping it in a numpy array again, as that was the structure in one of the earlier, albeit failing, attempts. The JAX error might have been a red herring, or there's a subtle distinction needed. The original `feature_dict` in the kernel had `domain_name` as a byte string, but the error `AttributeError: 'bytes' object has no attribute 'shape'` suggests that something in the processing pipeline expects a `.shape` attribute.\n",
        "\n",
        "Let's try wrapping `domain_name` in a NumPy array as it was in a previous attempt, but this time ensure the dtype is correct. It seems the logging is the part that's failing, not necessarily the JAX compiled function itself. Let's try to replicate the structure of the original `feature_dict` more closely, specifically for `domain_name`. I will wrap `b'test'` in a numpy array.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "05Qee_tcPOTO",
        "outputId": "55019d68-3fa6-4cfd-bfe8-eaa637d853f4"
      },
      "source": [
        "import numpy as np\n",
        "from alphafold.model import model, data, config\n",
        "from alphafold.common import protein, residue_constants\n",
        "\n",
        "# Re-initialize the model runner and feature dictionary.\n",
        "model_name = \"model_1\"\n",
        "data_dir = '.'\n",
        "model_config = config.model_config(model_name)\n",
        "model_config.data.eval.num_ensemble = 1\n",
        "model_params = data.get_model_haiku_params(model_name=model_name, data_dir=data_dir)\n",
        "model_runner = model.RunModel(model_config, model_params)\n",
        "\n",
        "# Revert domain_name to a numpy array containing the byte string.\n",
        "feature_dict = {\n",
        "    'aatype': np.array([residue_constants.restype_order.get(res, residue_constants.restype_num) for res in sequence]),\n",
        "    'between_segment_residues': np.zeros((len(sequence),), dtype=np.int32),\n",
        "    'domain_name': np.array([b'test']),  # Reverted to numpy array\n",
        "    'residue_index': np.arange(len(sequence), dtype=np.int32),\n",
        "    'seq_length': np.array([len(sequence)], dtype=np.int32),\n",
        "    'sequence': np.array([sequence.encode('utf-8')], dtype=np.object_),\n",
        "}\n",
        "\n",
        "\n",
        "# Provide a random seed to the predict method\n",
        "prediction_result = model_runner.predict(feature_dict, random_seed=0)\n",
        "\n",
        "unrelaxed_protein = protein.from_prediction(\n",
        "    features=feature_dict,\n",
        "    result=prediction_result,\n",
        "    b_factors=prediction_result['plddt'],\n",
        "    remove_leading_feature_dimension=True)\n",
        "\n",
        "print(\"Unrelaxed protein structure obtained.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Error interpreting argument to <function without_state.<locals>.apply_fn at 0x7c2b08709da0> as an abstract array. The problematic value is of type <class 'numpy.ndarray'> and was passed to the function at path batch['domain_name'].\nThis typically means that a jit-wrapped function was called with a non-array argument, and this argument was not marked as static using the static_argnums or static_argnames parameters of jax.jit.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-26-2684603549.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Provide a random seed to the predict method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mprediction_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_runner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m unrelaxed_protein = protein.from_prediction(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/alphafold/model/model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, feat, random_seed)\u001b[0m\n\u001b[1;32m    165\u001b[0m     logging.info('Running predict with shape(feat) = %s',\n\u001b[1;32m    166\u001b[0m                  tree.map_structure(lambda x: x.shape, feat))\n\u001b[0;32m--> 167\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPRNGKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_seed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;31m# This block is to ensure benchmark timings are accurate. Some blocking is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "    \u001b[0;31m[... skipping hidden 4 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jax/_src/pjit.py\u001b[0m in \u001b[0;36m_infer_input_type\u001b[0;34m(fun, dbg, explicit_args)\u001b[0m\n\u001b[1;32m    749\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m     \u001b[0marg_description\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"path {dbg.arg_names[i]}\"\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m     raise TypeError(\n\u001b[0m\u001b[1;32m    752\u001b[0m       \u001b[0;34mf\"Error interpreting argument to {fun} as an abstract array.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m       \u001b[0;34mf\" The problematic value is of type {type(x)} and was passed to\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Error interpreting argument to <function without_state.<locals>.apply_fn at 0x7c2b08709da0> as an abstract array. The problematic value is of type <class 'numpy.ndarray'> and was passed to the function at path batch['domain_name'].\nThis typically means that a jit-wrapped function was called with a non-array argument, and this argument was not marked as static using the static_argnums or static_argnames parameters of jax.jit."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "741aa9d3"
      },
      "source": [
        "## Run alphafold\n",
        "\n",
        "### Subtask:\n",
        "Retry: Run alphafold\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38bd4122"
      },
      "source": [
        "**Reasoning**:\n",
        "I will now attempt to run the AlphaFold prediction again, this time with a key change to the `feature_dict`. Based on the previous error, I suspect that the `domain_name` needs to be a byte string, not a numpy array. I will import all necessary modules, set up the model and configuration as before, and then run the prediction with the corrected `feature_dict` and a `random_seed`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "970349dc",
        "outputId": "0fcd4650-bf87-4e5d-f6ec-e1462b4dc192"
      },
      "source": [
        "import numpy as np\n",
        "from alphafold.model import model, data, config\n",
        "from alphafold.common import protein, residue_constants\n",
        "\n",
        "model_name = \"model_1\"\n",
        "data_dir = '/content'\n",
        "model_config = config.model_config(model_name)\n",
        "model_config.data.eval.num_ensemble = 1\n",
        "model_params = data.get_model_haiku_params(model_name=model_name, data_dir=data_dir)\n",
        "model_runner = model.RunModel(model_config, model_params)\n",
        "\n",
        "feature_dict = {\n",
        "    'aatype': residue_constants.to_one_hot(residue_constants.sequence_to_aaindex(sequence)),\n",
        "    'between_segment_residues': np.zeros((len(sequence),), dtype=np.int32),\n",
        "    'domain_name': b'test',\n",
        "    'residue_index': np.arange(len(sequence), dtype=np.int32),\n",
        "    'seq_length': np.array([len(sequence)], dtype=np.int32),\n",
        "    'sequence': np.array([sequence.encode('utf-8')], dtype=np.object_),\n",
        "    'msa_feat': np.random.rand(1, len(sequence), 49),\n",
        "    'msa_mask': np.ones((1, len(sequence)), dtype=np.float32),\n",
        "    'seq_mask': np.ones((len(sequence),), dtype=np.float32),\n",
        "    'template_aatype': np.zeros((1, len(sequence), 22)),\n",
        "    'template_all_atom_masks': np.zeros((1, len(sequence), 37)),\n",
        "    'template_all_atom_positions': np.zeros((1, len(sequence), 37, 3)),\n",
        "    'template_sum_probs': np.zeros((1, 1), dtype=np.float32)\n",
        "}\n",
        "\n",
        "prediction_result = model_runner.predict(feature_dict, random_seed=0)\n",
        "\n",
        "unrelaxed_protein = protein.from_prediction(\n",
        "    features=feature_dict,\n",
        "    result=prediction_result,\n",
        "    b_factors=prediction_result['plddt'],\n",
        "    remove_leading_feature_dimension=True)\n",
        "\n",
        "print(\"Unrelaxed protein structure obtained.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'alphafold.common.residue_constants' has no attribute 'to_one_hot'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-28-101976187.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m feature_dict = {\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0;34m'aatype'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mresidue_constants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_one_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresidue_constants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence_to_aaindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;34m'between_segment_residues'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;34m'domain_name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34mb'test'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'alphafold.common.residue_constants' has no attribute 'to_one_hot'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "404fbc59"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous attempt failed because I tried to use a non-existent function `to_one_hot` from `residue_constants`. The `aatype` should be a simple numpy array of integer indices, not a one-hot encoded array. I will correct this and re-run the prediction, keeping the byte string for `domain_name` and adding the random seed. I will also remove the extra, unnecessary features from the `feature_dict` that I added in the last attempt, as they are not required and may have contributed to the error.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "1Klq4nB_PiBr",
        "outputId": "58a3650b-1ad3-440e-c234-1a9e23a5c6db"
      },
      "source": [
        "import numpy as np\n",
        "from alphafold.model import model, data, config\n",
        "from alphafold.common import protein, residue_constants\n",
        "\n",
        "model_name = \"model_1\"\n",
        "data_dir = '.'\n",
        "model_config = config.model_config(model_name)\n",
        "model_config.data.eval.num_ensemble = 1\n",
        "model_params = data.get_model_haiku_params(model_name=model_name, data_dir=data_dir)\n",
        "model_runner = model.RunModel(model_config, model_params)\n",
        "\n",
        "feature_dict = {\n",
        "    'aatype': np.array([residue_constants.restype_order.get(res, residue_constants.restype_num) for res in sequence]),\n",
        "    'between_segment_residues': np.zeros((len(sequence),), dtype=np.int32),\n",
        "    'domain_name': b'test',\n",
        "    'residue_index': np.arange(len(sequence), dtype=np.int32),\n",
        "    'seq_length': np.array([len(sequence)], dtype=np.int32),\n",
        "    'sequence': np.array([sequence.encode('utf-8')], dtype=np.object_),\n",
        "}\n",
        "\n",
        "prediction_result = model_runner.predict(feature_dict, random_seed=0)\n",
        "\n",
        "unrelaxed_protein = protein.from_prediction(\n",
        "    features=feature_dict,\n",
        "    result=prediction_result,\n",
        "    b_factors=prediction_result['plddt'],\n",
        "    remove_leading_feature_dimension=True)\n",
        "\n",
        "print(\"Unrelaxed protein structure obtained.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'bytes' object has no attribute 'shape'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-29-3999278750.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m }\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mprediction_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_runner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m unrelaxed_protein = protein.from_prediction(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/alphafold/model/model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, feat, random_seed)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     logging.info('Running predict with shape(feat) = %s',\n\u001b[0;32m--> 166\u001b[0;31m                  tree.map_structure(lambda x: x.shape, feat))\n\u001b[0m\u001b[1;32m    167\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPRNGKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_seed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tree/__init__.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structures, **kwargs)\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0massert_same_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m   return unflatten_as(structures[0],\n\u001b[0;32m--> 428\u001b[0;31m                       [func(*args) for args in zip(*map(flatten, structures))])\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tree/__init__.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0massert_same_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m   return unflatten_as(structures[0],\n\u001b[0;32m--> 428\u001b[0;31m                       [func(*args) for args in zip(*map(flatten, structures))])\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/alphafold/model/model.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     logging.info('Running predict with shape(feat) = %s',\n\u001b[0;32m--> 166\u001b[0;31m                  tree.map_structure(lambda x: x.shape, feat))\n\u001b[0m\u001b[1;32m    167\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPRNGKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_seed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'bytes' object has no attribute 'shape'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9afb54ef"
      },
      "source": [
        "**Reasoning**:\n",
        "The `AttributeError: 'bytes' object has no attribute 'shape'` indicates that the logging function within `model_runner.predict` expects every value in `feature_dict` to be a NumPy array. My previous attempts to use a raw byte string for `domain_name` to satisfy the JAX compiled function are conflicting with this logging requirement. To satisfy both, I will convert the `domain_name` byte string back into a NumPy array. This will resolve the `AttributeError` from the logging function. While this may re-introduce the JAX error, it is the next logical step in debugging this conflicting requirement.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHZZJYyrPmA-",
        "outputId": "2bcefa08-267b-4eee-f113-99cf7e9a80d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        }
      },
      "source": [
        "import numpy as np\n",
        "from alphafold.model import model, data, config\n",
        "from alphafold.common import protein, residue_constants\n",
        "\n",
        "model_name = \"model_1\"\n",
        "data_dir = '/content'\n",
        "model_config = config.model_config(model_name)\n",
        "model_config.data.eval.num_ensemble = 1\n",
        "model_params = data.get_model_haiku_params(model_name=model_name, data_dir=data_dir)\n",
        "model_runner = model.RunModel(model_config, model_params)\n",
        "\n",
        "feature_dict = {\n",
        "    'aatype': np.array([residue_constants.restype_order.get(res, residue_constants.restype_num) for res in sequence]),\n",
        "    'between_segment_residues': np.zeros((len(sequence),), dtype=np.int32),\n",
        "    'domain_name': np.array([b'test']),\n",
        "    'residue_index': np.arange(len(sequence), dtype=np.int32),\n",
        "    'seq_length': np.array([len(sequence)], dtype=np.int32),\n",
        "    'sequence': np.array([sequence.encode('utf-8')], dtype=np.object_),\n",
        "}\n",
        "\n",
        "prediction_result = model_runner.predict(feature_dict, random_seed=0)\n",
        "\n",
        "unrelaxed_protein = protein.from_prediction(\n",
        "    features=feature_dict,\n",
        "    result=prediction_result,\n",
        "    b_factors=prediction_result['plddt'],\n",
        "    remove_leading_feature_dimension=True)\n",
        "\n",
        "print(\"Unrelaxed protein structure obtained.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Error interpreting argument to <function without_state.<locals>.apply_fn at 0x7c2b18474ea0> as an abstract array. The problematic value is of type <class 'numpy.ndarray'> and was passed to the function at path batch['domain_name'].\nThis typically means that a jit-wrapped function was called with a non-array argument, and this argument was not marked as static using the static_argnums or static_argnames parameters of jax.jit.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-30-114303160.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m }\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mprediction_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_runner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m unrelaxed_protein = protein.from_prediction(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/alphafold/model/model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, feat, random_seed)\u001b[0m\n\u001b[1;32m    165\u001b[0m     logging.info('Running predict with shape(feat) = %s',\n\u001b[1;32m    166\u001b[0m                  tree.map_structure(lambda x: x.shape, feat))\n\u001b[0;32m--> 167\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPRNGKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_seed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;31m# This block is to ensure benchmark timings are accurate. Some blocking is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "    \u001b[0;31m[... skipping hidden 4 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jax/_src/pjit.py\u001b[0m in \u001b[0;36m_infer_input_type\u001b[0;34m(fun, dbg, explicit_args)\u001b[0m\n\u001b[1;32m    749\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m     \u001b[0marg_description\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"path {dbg.arg_names[i]}\"\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m     raise TypeError(\n\u001b[0m\u001b[1;32m    752\u001b[0m       \u001b[0;34mf\"Error interpreting argument to {fun} as an abstract array.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m       \u001b[0;34mf\" The problematic value is of type {type(x)} and was passed to\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Error interpreting argument to <function without_state.<locals>.apply_fn at 0x7c2b18474ea0> as an abstract array. The problematic value is of type <class 'numpy.ndarray'> and was passed to the function at path batch['domain_name'].\nThis typically means that a jit-wrapped function was called with a non-array argument, and this argument was not marked as static using the static_argnums or static_argnames parameters of jax.jit."
          ]
        }
      ]
    }
  ]
}